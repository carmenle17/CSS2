{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Le_Carmen_problem_set_9.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uShnGl5gDQI_"
      },
      "source": [
        "# **Block 1: Import only “seaborn”, “pandas”, “numpy”, “matplotlib.pyplot”, and “from sklearn.linear_model import LinearRegression”. Import the data here as well using seaborn (data = sns.load_dataset('geyser'))**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVjfvUwJD1NC"
      },
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "data = sns.load_dataset('geyser')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaR-Hw-rlwuB"
      },
      "source": [
        "# **Block 2 (with EXTRA CREDIT function): Create your own k-fold cross validation code with the number of folds being 10.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymRqo2nV1m0T"
      },
      "source": [
        "def kfold_score(x,y,folds):\n",
        "  \n",
        "  training_r2 = []\n",
        "  testing_r2 = []\n",
        "\n",
        "  # randomize the order of the data\n",
        "  data.sample(frac=1)\n",
        "\n",
        "  X = np.array(x) \n",
        "  X = X.reshape(len(X),1)\n",
        "  y = np.array(y) \n",
        "\n",
        "  for i in range(0,folds):  # number of folds is number of times you go through for loop\n",
        "\n",
        "      # indexes for making the folds; divide total length of data by 10 folds\n",
        "      j = int(i* (len(X)/folds)) \n",
        "      f = int(j + (len(X)/folds))\n",
        "      \n",
        "      # index into X and y for testing and training based on the folds\n",
        "      Xtest = X[j:f]\n",
        "\n",
        "      # turn Xtrain into an array\n",
        "      Xtrain1 = X[0:j] \n",
        "      Xtrain2 = X[f:]\n",
        "      Xtrain = np.concatenate((Xtrain1, Xtrain2))\n",
        "\n",
        "      ytest = y[j:f]\n",
        "\n",
        "      # turn ytrain into an array\n",
        "      ytrain1 = y[0:j]\n",
        "      ytrain2 = y[f:]\n",
        "      ytrain = np.concatenate((ytrain1,ytrain2))\n",
        "\n",
        "      # linear regression model fitting\n",
        "      model = LinearRegression()\n",
        "      model.fit(Xtrain.reshape(len(Xtrain),1), ytrain)\n",
        "\n",
        "      # r2 scores\n",
        "      training_r2.append(model.score(Xtrain.reshape(len(Xtrain),1), ytrain))\n",
        "      testing_r2.append(model.score(Xtest.reshape(len(Xtest),1), ytest))\n",
        "\n",
        "      avg = np.mean(testing_r2)\n",
        "      std = np.std(testing_r2)\n",
        "    \n",
        "  return avg, std"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIuIY_74l1ZA"
      },
      "source": [
        "# **Block 3: Print the average and standard deviation of the R^2 value for the different folds**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL0b2Sh_qEiq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc38ea45-a6f4-4142-dc33-3b5e877f26f2"
      },
      "source": [
        "print('k=3:')\n",
        "avg, std = kfold_score(data['duration'], data['waiting'], 3)   # unpack tuple that is returned from the function\n",
        "print('average R^2:', avg)\n",
        "print('std R^2:', std)\n",
        "print('')\n",
        "\n",
        "print('k=5:')\n",
        "avg, std = kfold_score(data['duration'], data['waiting'], 5)\n",
        "print('average R^2:', avg)\n",
        "print('std R^2:', std)\n",
        "print('')\n",
        "\n",
        "print('k=10:')\n",
        "avg, std = kfold_score(data['duration'], data['waiting'], 10)\n",
        "print('average R^2:', avg)\n",
        "print('std R^2:', std)\n",
        "print('')\n",
        "\n",
        "print('k=20:')\n",
        "avg, std = kfold_score(data['duration'], data['waiting'], 20)\n",
        "print('average R^2:', avg)\n",
        "print('std R^2:', std)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k=3:\n",
            "average R^2: 0.800452106299595\n",
            "std R^2: 0.02982886623826577\n",
            "\n",
            "k=5:\n",
            "average R^2: 0.8064121141245482\n",
            "std R^2: 0.021643210021753557\n",
            "\n",
            "k=10:\n",
            "average R^2: 0.7982771830742063\n",
            "std R^2: 0.06730037541257397\n",
            "\n",
            "k=20:\n",
            "average R^2: 0.7779123591464386\n",
            "std R^2: 0.14587623229874574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_4BuKBdl365"
      },
      "source": [
        "# **Block 4: In a text block, interpret this result**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y5PFf8xlBWq"
      },
      "source": [
        "The average R^2 value tells us how well the different partitions of X data (duration) predict the Y values (waiting). The 0.798 value when k=10 shows that in general, our model predicts the data pretty well even when going through different iterations of data. \n",
        "\n",
        "The standard deviation R^2 value tells us how much variance there is in our model. The .067 value when k=10 is pretty low, which shows that there is not much variance in our data, and that the splitting of the data doesn't affect our model."
      ]
    }
  ]
}